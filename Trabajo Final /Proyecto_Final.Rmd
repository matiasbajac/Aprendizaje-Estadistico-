---
title: "Proyecto Final"
author: "Matias Bajac, Manuel Toledo y Lucas Pescetto"
date: "`r Sys.Date()`"
output: html_document
bibliography: referencias.bib
nocite: "@*"
---

```{r setup, include=FALSE, echo = T}

knitr::opts_chunk$set(echo = FALSE,message=F,warning=F)
library(factoextra)
library(tidyverse)
library(haven) 
library(vcd)
library(ggcorrplot)
library(tidymodels)
library(gridExtra)
library(ggmosaic)
library(vip)
library(DALEXtra)
library(ggrepel)
library(knitr)
library(FactoMineR)
library(pROC)
library(baguette)
library(vip)

tema <- theme(
  text = element_text(color = "#333333"),
  plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
  plot.subtitle = element_text(size = 12, margin = margin(b = 10)),
  plot.caption = element_text(size = 10, face = "italic", hjust = 1),
  axis.title = element_text(size = 12, face = "bold"),
  axis.text = element_text(size = 10),
  axis.line = element_line(color = "#666666"),
  axis.ticks = element_line(color = "#666666"),
  panel.background = element_rect(fill = "#f9f9f9"),
  panel.grid.major = element_line(color = "#dcdcdc", linetype = "dotted"),
  panel.grid.minor = element_blank(),
  legend.background = element_rect(fill = "#ffffff", color = NA),
  legend.key = element_rect(fill = NA),
  legend.title = element_text(face = "bold"),
  legend.text = element_text(size = 10),
  strip.background = element_rect(fill = "#e3e3e3", color = NA),
  strip.text = element_text(face = "bold", size = 12)
)

colores <- c(
  "#4E79A7", # Azul clásico
  "#F28E2B", # Naranja cálido
  "#E15759", # Rojo coral
  "#76B7B2", # Verde menta
  "#59A14F"  # Verde fresco
)

#Función para eliminar los nombres de dummys
dummys_fuera <- function(variables) {
  variables <- str_replace_all(variables, "_X\\d+$", "")
  variables <- str_replace_all(variables,"_(bajo|media|alta|no.sabe)$","")
  variables <- str_replace_all(variables, "_[A-Z].*", "")
  variables <- unique(variables)
  return(variables)
}

```

```{r echo = FALSE}
act_res <- readRDS("datos/base_final.RDS")
```


# Introducción

La predicción del desempeño académico de los estudiantes resulta de interés tanto en el ámbito académico como en el de las políticas educativas. Se destaca el potencial de los modelos predictivos para la toma decisiones informadas y la creación de estrategias que mejoren los índices de aprobación así como la experiencia de los estudiantes.

En este trabajo se aplican una serie de modelos con el objetivo de predecir si los estudiantes de la facultad aprobarán o no el curso el que se inscriban, en función del contexto del cual vienen y su interacción con el curso, entre otros predictores.

Los modelos de clasificación que se ponen a prueba son algunos de los estudiados en el curso de Aprendizaje Estadístico Supervisado : random forest, regresión logística , k vecinos mas cercano. 

Los datos utilizados tienen como fuente el sistema de bedelías de la facultad de Ciencias Económicas y Administración de la Universidad de la República. Se tiene información de los estudiantes que se inscribieron en cualquiera de las carreras disponibles en facultad, en los años 2018 y 2019. Además, se cuenta con datos de las actividades (cursos, exámenes) en las cuales participaron dichos estudiantes, entre los años 2018 y 2021 , como así de la información de los datos FormA.

## Descripción del problema

Se plantea predecir si el estudiante va a aprobar un curso, en función de las siguientes variables:

- **Sexo**
- **Edad_inicial**: a la fecha en que el estudiante interactuó con el curso por primera vez 
- **Edad_final**: a la fecha en que el estudiante interactuó con el curso por última vez
- **Lugar de nacimiento**: Montevideo, Interior o Etranjero 
- **Lugar de egreso de EMS**: Montevideo o Interior  
- **Tipo de institución en la que aprobó EMS**: toma los valores 1 si fue a Institución privada, 2 Privada técnica,  3 pública secundria , 4 pública técnica. 
- **Fecha de egreso de EMS**: año en la que egreso de secundaria.
- **mat**: materia 
- **Carrera a la cuál está inscripto el estudiante**: Se tomaron las carreras de Licenciatura en Economiía, Licenciatura en Administración y Contador Público 

A su vez se crearon variables:

- **Edad_inicial** Diferencia entre la fecha de egreso de EMS y la fecha de inscripción a la facultad 
- **Edad_inicial** Diferencia entre la fecha de egreso de EMS y la fecha en que el estudiante interactuó con el curso por última vez
-  **Cursadas** Cantidad de veces que participó del curso
- **Examenes** Cantidad de veces que dio el examen del curso
- **lic_economia**, **lic_administracion**, **contador**: indican si el estudiante está inscripto en cada carrera.

Con el objetivo de mejorar la interpretabilidad de los resultados, en principio se restringe el problema a las materias de primer semestre, que son comunes a todas las carreras de grado consideradas: Contador Público, Licenciatura en Administración y Licenciatura en Economía. Las materias son:
- Conceptos Contables
- Introducción a la Microeconomía
- Cálculo I
- Cálculo I/A (es excluyente con Cálculo I ya que es una versión reducida de la anterior)
- Gestión y Administración de las Organizaciones I

## Estructura de los datos y pre-procesamiento

Como se mencionó en la introducción, los datos corresponden a las actividades llevadas a cabo entre 2018 y 2021 en la facultad, para estudiantes inscriptos en 2018 y 2019.

Antes de describir la estructura de los datos, es importante aclarar que para las materias consideradas existen dos métodos de aprobación: el primero consiste en cursar la materia y rendir dos parciales a lo largo del semestre, mientras que el segundo implica tomar un examen al final de cada semestre. En ninguna de las modalidades es obligatorio asistir a clases, y cada estudiante puede optar por la modalidad que prefiera, incluso alternando entre ambas hasta lograr aprobar la materia. Existe un límite en la cantidad de veces que el estudiante puede acceder a la modalidad de los parciales, pero el mismo no se aplicó durante los años de pandemia.

Los insumos utilizados para este trabajo están distribuidos en 4 datasets:

1. Estudiantes: es una lista de los estudiantes inscriptos en 2018 y 2019 con atributos de los mismos, como fecha de nacimiento, sexo, información sobre la institución en la que cursó EMS, entre otros.

2. Actividades: contiene todas las instancias en las que un estudiante cursó alguna materia en el período de referencia. Incluye un identificador del estudiante, de la materia y una variable que indica si el estudiante aprobó la instancia, además de la fecha del resultado. Dado que un estudiante puede estar inscripto en varias carreras al mismo tiempo, las actividades están repetidas para cada carrera en la que está inscripto un estudiante.

3. Resultados: contiene todas las instancias en las que un estudiante cursó alguna materia y la aprobó; y todas las instancias en las que un estudiante tomó un examen (independientemente de si lo aprobó o no). Incluye el identificador de estudiante y de materia, la fecha del resultado, el tipo de aprobación (curso o examen), la variable indicadora de si la materia fue aprobada, la nota de aprobación y la cantidad de créditos que corresponden a dicha materia.

4. Respuestas al FormA, una encuesta obligatoria que tienen que completar los estudiantes cada año. En este caso particular se utilizarán las respuestas dadas el primer año de carrera. El formulario nos otorga información sobre las condiciones de vida de los estudiantes, como con quienes conviven o si es que trabajan y la cantidad de horas que dedican al trabajo.

A continuación se detallan las transformaciones llevadas a cabo a los datos y la estructura utilizada para entrenar los modelos:

1. Se toma la tabla de actividades y se conservan solamente aquellas correspondientes a las tres carreras de referencia y las 5 materias de primer semestre. 
2. Se descartan las actividades repetidas de estudiantes que están inscriptos en varias carreras, y se generan variables indicadoras de las carreras en las que está inscripto cada estudiante.
3. Para cada combinación de estudiante-materia se genera una agregación de todas las instancias, construyendo las variables:
  - fecha_activ_inicial: la fecha del resultado de la primera vez que cursó la materia
  - fecha_activ_final: la fecha del resultado de la última vez que cursó la materia
  - cursadas = la cantidad de veces que cursó la materia
  - aprobada_act = indica si aprobó la materia en la última instancia
4. Se sigue un procedimiento similar para la tabla de resultados, generando de forma análoga las variables fecha_res_inicial, fecha_res_final, exámenes, tipo_aprobacion_final y aprobada_res. De esta tabla también se descartan algunas categorías residuales de resultados, por ejemplo reválidas, conservando solamente cursos y exámenes.
5. Se vinculan las tablas de actividades y resultados utilizando los identificadores de estudiante y materia, y se unifica la variable aprobada, que vale 1 si el estudiante aprobó la materia en cualquiera de las modalidades. Además se modifica la variable tipo_resultado, de forma que indique la modalidad de aprobación de la última vez que el estudiante interactuó con el curso.
6. Se vinculan los atributos de interés de la tabla de estudiantes, y se calculan variables como la edad del estudiante al momento de la última interacción con el curso. De la tabla de estudiantes se seleccionan las siguientes variables:
  - dif_entender, dif_ver, dif_oir, dif_caminar: indican si el estudiante presenta alguna dificultad en las dimensiones enumeradas.
  - pareja: indica si el estudiante tiene pareja
  - vive_con_hijos: indica si el estudiante tiene hijos viviendo en su hogar
  - n_padres_vive: indica la cantidad de padres con los que vive el estudiante (0, 1, o 2)
  - h_trabajo: se crean categorías según la carga horaria que trabaja el estudiante:
    - 0: no trabaja
    - 1: 1-20 horas
    - 2: 21-30 horas
    - 3: 31-40 horas
    - 4: más de 40 horas
  - educ_madre, educ_padre: el máximo nivel educativo alcanzado por los padres.
  - tipo_vivienda: 
    - 1: casa/apartamento
    - 2: pensión/hotel
    - 3: hogar estudiantil
    - 4: otro

# Análisis Exploratorio

La variable a predecir es la variable indicadora que explicita si el estudiante aprobó o no la materia en la última instancia en la que interactuó con ella. Por lo tanto, se enfrenta un problema de clasificación donde la variable de respuesta tiene dos categorías posibles: aprobó / no aprobó. 

Para el análisis exploratorio, se propone analizar la relación entre esta variable y las variables predictoras, para ver en qué medida éstas determinan que el curso sea aprobado o no.

En primer lugar, se cuenta con información de `r nrow(act_res %>% distinct(id))` estudiantes, los cuales interactuaron con `r nrow(act_res)` cursos. A continuación se caracterizan brevemente los estudiantes en cuestión, que son aquellos que se inscribieron a alguna de las carreras consideradas en 2018 y 2019.

La figura 1a muestra la distribución de edad. Se verifica que la mayoría de los estudiantes tienen alrededor de 20 años, mientras que el de mayor edad tiene `r round(max(act_res$edad_final))` años.

Por su parte, la figura 1c muestra que la mayoría de los estudiantes nacieron en Montevideo y completaron la secundaria en el mismo lugar, aunque también se hacen notar los estudiantes nacidos y con estudios en el interior del país. Finalmente, se observa que alrededor del 50% de los estudiantes completaron la educación secundaria en una institución pública, mientras que la otra mitad está repartida en partes casi iguales entre instituciones privadas y técnicas; y una minoría completó la secundaria en el exterior. 


```{r sobre_estudiantes, fig.cap="figura 1: caracterización de los estudiantes"}
est <- act_res %>% 
  distinct(id, .keep_all = T)

plot1 <- ggplot(data = est, aes(x = edad_final)) +
  geom_histogram(fill = "#4E79A7", col = "black", bins = 25) +
  labs(x = "edad", y = "estudiantes") +
  tema

plot2 <- ggplot(data = est, aes(x = sexo, fill = sexo)) +
  geom_bar(col = "black") +
  labs(x = "sexo", y = "estudiantes") +
  scale_fill_manual(values = c("#4E79A7", "#F28E2B"), breaks = c("M", "F")) +
  tema

# install.packages("devtools")
#devtools::install_github("haleyjeppson/ggmosaic")

plot3 <-  ggplot(data= est) + 
geom_mosaic(aes(x = product(zona_nac), fill = zona_ems), color = "black") +
  scale_fill_manual(values = c("#4E79A7", "#F28E2B")) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "nacimiento", y = "Proporción (%)", fill = "egreso ems") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  tema
# 


plot4 <- ggplot(data = est, aes(x = tipo_inst_proc, fill = tipo_inst_proc)) +
  geom_bar(col = "black") +
  labs(x = "tipo de institución ems", y = "estudiantes") +
  scale_fill_manual(values = c("#4E79A7", "#F28E2B", "#E15759", "#59A14F"), breaks = c(1, 2, 3, 4)) +
  scale_x_discrete(breaks = c(1, 2, 3, 4), labels = c("Privada", "Pública secundaria", "Pública técnica", "Extranjero")) +  theme(axis.text.x = element_text(angle = 45, hjust = 1))  +
  tema +
  guides(fill = "none") 


grid.arrange(plot1, plot2, plot3,plot4)
```

Para comenzar a analizar el desempeño de los estudiantes, es necesario comparar la variable de respuesta, "aprobada", con las explicativas. Como la mayoría de las variables explicativas son, al igual que la de respuesta, categóricas, resultan útiles los gráficos de mosaico. Para visualizar fácilmente los distintos cruces entre variables se desarrolló una aplicación con *shiny* que dibuja los mosaicos en función de las variables seleccionadas por el usuario. Se puede acceder a esta aplicación en el notebook 'shiny.Rmd' (no fue posible subir la app a shinyservers por incompatibilidad con el paquete *ggmosaic*). 

A continuación se presentan algunos de los mosaicos donde se destaca la asociación entre las variables. La figura 2 permite ver la proporción de cursos aprobados según el tipo de institución donde el estudiante cursó secundaria. Los estudiantes egresados de instituciones privadas suelen aprobar una mayor proporción de los cursos, seguidos por los provenientes de instituciones públicas secundarias.

La figura 3 muestra la proporción de cursos aprobados en función de varias características relacionadas a los vínculos del estudiante. Por ejemplo, se observa que los estudiantes que tienen hijos viviendo en su hogar aprueban menos cursos respecto a los que no; o que los estudiantes viviendo con sus dos padres aprueban más cursos que aquellos que viven con uno solo o ninguno.

```{r, fig.cap = "Figura 2: proporción de cursos aprobados según tipo de institución de ed. secundaria."}

act_res %>% 
  ggplot() +
  geom_mosaic(aes(x = product(tipo_inst_proc), fill = aprobada), color = "black") +
  scale_fill_manual(values = c("#E15759", "#59A14F")) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "tipo inst. secundaria", y = "Proporción (%)", fill = "aprobada") +
  tema

```

```{r fig.cap = "Figura 3: proporción de cursos aprobados en función de los vínculos/composición del hogar del estudiante."}

plot1 <- act_res %>% 
  ggplot() +
  geom_mosaic(aes(x = product(vive_con_hijos), fill = aprobada), color = "black") +
  scale_fill_manual(values = c("#E15759", "#59A14F")) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "¿tiene hijos viviendo en su hogar?", y = "Proporción (%)", fill = "curso aprobado") +
  tema

leyenda <- cowplot::get_legend(plot1)

plot1 <- act_res %>% 
  ggplot() +
  geom_mosaic(aes(x = product(vive_con_hijos), fill = aprobada), show.legend = F, color = "black") +
  scale_fill_manual(values = c("#E15759", "#59A14F")) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "¿tiene hijos viviendo en su hogar?", y = "Proporción (%)", fill = "curso aprobado") +
  tema

plot2 <- act_res %>% 
  ggplot() +
  geom_mosaic(aes(x = product(pareja), fill = aprobada), show.legend = F, color = "black") +
  scale_fill_manual(values = c("#E15759", "#59A14F")) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "¿tiene pareja?", y = "Proporción (%)", fill = "curso aprobado") +
  tema

plot3 <- act_res %>% 
  ggplot() +
  geom_mosaic(aes(x = product(n_padres_vive), fill = aprobada), show.legend = F, color = "black") +
  scale_fill_manual(values = c("#E15759", "#59A14F")) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "¿con cuántos padres vive?", y = "Proporción (%)", fill = "curso aprobado") +
  tema

plot4 <- act_res %>% 
  mutate(tipo_vivienda = factor(tipo_vivienda, levels = c(1, 2, 3, 4), labels = c("Casa/Apartamento", "Pensión/hotel", "Hogar estudiantil", "Otro"))) %>% 
  ggplot() +
  geom_mosaic(aes(x = product(educ_madre), fill = aprobada), show.legend = F, color = "black") +
  scale_fill_manual(values = c("#E15759", "#59A14F")) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "nivel educativo de la madre", y = "Proporción (%)", fill = "curso aprobado") +
  guides(fill = "none") +
  tema

grid.arrange(arrangeGrob(
    textGrob(""),            # Espacio vacío arriba a la izquierda
    leyenda,                 # Leyenda arriba a la derecha
    ncol = 2,                # Dos columnas (vacío y leyenda)
    widths = c(3, 1)),
    arrangeGrob(plot1, plot2, plot3, plot4, ncol = 2), heights = c(2, 10))

```

Para el resto de las variables categóricas se observan patrones dentro de lo esperado. Por ejemplo, los estudiantes con alguna dificultad para ver, caminar o entender aprueban una proporción un tanto menor de cursos. Para otras variables, como el sexo o el lugar donde realizó estudios secundarios, no se observan patrones de asociación claros respecto a aprobar o no un curso.  

El siguiente gráfico muestra la distribución de edades según si el curso está aprobado o no. No parece haber grandes diferencias, aunque los cursos aprobados están asociados a edades levemente más bajas.

```{r}

act_res %>% 
  ggplot(aes(x = aprobada, y = edad_final, fill = aprobada)) +
  geom_boxplot() +
  scale_fill_manual(values = c("#E15759", "#59A14F")) +
  labs(x = "curso aprobado", y = "edad") +
  tema

```

Por último, se realiza un análisis de componentes principales para datos mixtos para ver cómo interactúan las variables entre sí. Las variables parecen tener influencias muy diferentes, pues de entre las primeras 10 dimensiones del análisis no se llega a explicar ni el 50% de la variabilidad entre los datos. De entre los dos primeros componentes destaca la influencia de la edad y el lugar de origen, aunque juntos sólo explican el 16,4% de la variabilidad.

```{r}
act_res_famd <- act_res |> 
  select(-id) #|> 
  # mutate(across(where(is.factor), ~ factor(., labels = paste0(cur_column(), "_", levels(.)))))
r_famd <- FAMD(act_res_famd,graph=F,ncp=10)
fviz_famd_var(r_famd, repel=T, choice="var")
kable(r_famd$eig, format="html")


```

# Entrenamiento de modelos predictivos

El siguiente paso en el análisis es entrenar distintos modelos con el fin de predecir la variable de respuesta: si el curso fue aprobado o no. Los modelos que se entrenan son los siguientes:

1. Discriminarte logístico con LASSO: Este es el modelo se utiliza para seleccionar variables, y así utilizar solo aquellas que sean relevantes. Se tunea el parámetro $\lambda$.

2. KNN (k vecinos más cercanos): se tunea la cantidad de vecinos

3. Random forest: se tunea el parámetro *min_n*, que determina en qué momento debe dejar de "crecer" cada árbol. El bosque se construye con 50 árboles.

4. Bagging: En este caso también se tunea el parámetro *min_n* y se utilizan 50 árboles.

El entrenamiento de los modelos se realiza en un workflow conjunto, donde se define una receta general para pre-procesar los datos, en la cuál se convierten las variables categóricas a dummies, y se normalizan las numéricas; y se integran las especificaciones de cada modelo y las estructuras de búsqueda de los parámetros a tunear.

Este proceso se hace con ayuda del paquete *targets* , que permite llevar a cabo el procesamiento en varios núcleos, optimizando el rendimiento. El mismo se define en el script "_targets.R", y al correrlo se almacenan los resultados de los modelos entrenados, que se presentan a continuación.

## Selección de variables con LASSO

Se ajusta un modelo de regresión logística aplicando el método de regularización de LASSO para la selección de variables.  Haciendo validación cruzada con 5 pliegues, se crea una grilla  exhaustiva para tunear el parámetro de penalidad ($\lambda$) y se selecciona las mejores variables posibles, es decir las que resultan en un $\lambda$ diferente a 0. Se termina excluyendo del modelo las variables relacionadas a la dificultad del estudiante, los exámenes que da el estudiante, tipo de vivienda, y si tiene pareja.

```{r lasso}

set.seed(501)


actres_split <- initial_split(act_res, prop = 0.8)
  
actres_train <- training(actres_split)

actres_test <-  testing(actres_split)



lasso_spec <- parsnip:: logistic_reg(penalty = tune(), mixture= 1) %>%  set_mode("classification") %>%  parsnip::set_engine("glmnet")

lasso_rec <- recipe(aprobada ~ ., data =actres_train )  %>% 
  update_role( id,new_role="id") %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_dummy(all_nominal_predictors())
   

lasso_fit = fit(lasso_spec, aprobada ~ ., data = actres_train) 


tune_wf <- workflow() |>
  add_recipe(lasso_rec) |>
  add_model(lasso_spec)

actres_res_cv <- vfold_cv(actres_train, v = 5) 
lambda_grid <- grid_regular(penalty(c(-3,-1)),  levels = 100) 
lasso_tune<- tune_grid(  
  tune_wf,
  resamples = actres_res_cv,
  grid = lambda_grid
)
best_metric <- lasso_tune |>
  select_best(metric = "accuracy")

final_lasso <- finalize_workflow(tune_wf, best_metric)

# Se eliminana las variables no relevantes
 
selected_vars <- final_lasso |>
  fit(actres_train) |>
  extract_fit_engine() |>
  vi(lambda = best_metric$penalty) |>
  filter(Importance > 0) |> 
  pull(Variable) |> 
  dummys_fuera()

actres_train_selected <- actres_train  %>%  dplyr::select(all_of(c(selected_vars, "aprobada")))

actres_train2 = actres_train %>%
  dplyr::select(-c("examenes","dif_oir","dif_caminar","dif_entender","dif_ver","tipo_vivienda","pareja"))

actres_test2 <- actres_test %>%
  dplyr::select(-c("examenes","dif_oir","dif_caminar","dif_entender","dif_ver","tipo_vivienda","pareja"))

actres_split2 <- actres_split
actres_split2$data <- actres_split2$data %>%
  dplyr::select(-c("examenes","dif_oir","dif_caminar","dif_entender","dif_ver","tipo_vivienda","pareja"))


saveRDS(actres_train2, "datos/train.RDS")
saveRDS(actres_test2, "datos/test.RDS")

```

Finalmente, como se observa en la figura 4, el valor seleccionado de penalidad según la precisión es cercano a 0, en particular vale `r round(best_metric$penalty, 4)`.

```{r lasso_graficos, fig.cap = "Figura 4: medidas de performance de Lasso en función de la penalización."}

autoplot(lasso_tune) + tema

```

# Resultados e interpretación

A continuación se presentan los resultados obtenidos en los modelos que se entrenaron.

```{r modelos}

library(targets)

# Pueden usar tar_make() para recalcular los modelos. Tardamos 3hs en correrlo.

#### NOTA IMPORTANTE
# Para descargar los datos de grid_results tienen que usar el paquete LFS de git
# el archivo es _targets/objects/grid_results

grid_results <- tar_read(grid_results)
best_results <- tar_read(best_results)

```

## Random Forest

```{r}

best_results_rf <- 
   grid_results %>% 
   extract_workflow_set_result("recipe_RF") %>% 
   select_best(metric = "accuracy")

rf_test_results <- 
    grid_results %>% 
    extract_workflow("recipe_RF") %>% 
    finalize_workflow(best_results_rf) %>% 
    last_fit(split = actres_split2)


mat_conf <- 
data.frame(rf_test_results$.predictions) |>
    count(aprobada, .pred_class) |> 
    mutate(.pred_class = factor(.pred_class,c(0,1))) 


mat_conf |> 
  ggplot(aes(x = aprobada, y = .pred_class)) +
  geom_tile(aes(fill = n)) +
  geom_text(aes(label = n), color = "white") +
  labs(x = "Observado", y = "Predicho") +
  theme(legend.position = "none")

```

Si se considera un punto de corte de 0.5, el random forest tiene una precisión de `r paste0(round((mat_conf$n[4] + mat_conf$n[1])/(nrow(actres_test2))*100, 1), "%")`, sensibilidad de `r paste0(round(mat_conf$n[4]/(mat_conf$n[4] + mat_conf$n[3])*100, 1), "%")` y especificidad de `r paste0(round(mat_conf$n[1]/(mat_conf$n[1] + mat_conf$n[2])*100, 1), "%")` en el conjunto de test.

## Regresión logística

```{r}


best_results_reglog <- 
   grid_results %>% 
   extract_workflow_set_result("recipe_Reg_log") %>% 
   select_best(metric = "accuracy")

reglog_test_results <- 
    grid_results %>% 
    extract_workflow("recipe_Reg_log") %>% 
    finalize_workflow(best_results_reglog) %>% 
    last_fit(split = actres_split2)


mat_conf <- 
data.frame(reglog_test_results$.predictions) |>
    count(aprobada, .pred_class) |> 
    mutate(.pred_class = factor(.pred_class,c(0,1))) 


mat_conf |> 
  ggplot(aes(x = aprobada, y = .pred_class)) +
  geom_tile(aes(fill = n)) +
  geom_text(aes(label = n), color = "white") +
  labs(x = "Observado", y = "Predicho") +
  theme(legend.position = "none")


```

Una vez seleccionadas las variables más significativas, vemos mediante la matriz de confusión, que hay un `r paste0(round(mat_conf$n[4]/(mat_conf$n[4] + mat_conf$n[3])*100, 1), "%")` de sensibilidad, `r paste0(round(mat_conf$n[1]/(mat_conf$n[1] + mat_conf$n[2])*100, 1), "%")` de especificidad y `r paste0(round((mat_conf$n[4] + mat_conf$n[1])/(nrow(actres_test2))*100, 1), "%")` de precisión.

## Bagging

```{r}
best_results_bagging <- 
   grid_results %>% 
   extract_workflow_set_result("recipe_Bagging") %>% 
   select_best(metric = "accuracy")

bagging_test_results <- 
    grid_results %>% 
    extract_workflow("recipe_Bagging") %>% 
    finalize_workflow(best_results_bagging) %>% 
    last_fit(split = actres_split2)


mat_conf <- 
data.frame(bagging_test_results$.predictions) |>
    count(aprobada, .pred_class) |> 
    mutate(.pred_class = factor(.pred_class,c(0,1))) 


mat_conf |> 
  ggplot(aes(x = aprobada, y = .pred_class)) +
  geom_tile(aes(fill = n)) +
  geom_text(aes(label = n), color = "white") +
  labs(x = "Observado", y = "Predicho") +
  theme(legend.position = "none")

```

A partir de la matriz de confusión, y con un corte en 0.5, se observa que el modelo de Random Forest con bagging tiene una precisión del `r paste0(round((mat_conf$n[4] + mat_conf$n[1])/(nrow(actres_test2))*100, 1), "%")`. En particular se destaca su sensibilidad de `r paste0(round(mat_conf$n[4]/(mat_conf$n[4] + mat_conf$n[3])*100, 1), "%")`, es decir que el modelo es bueno para identificar a aquellos estudiantes que aprueban los cursos. Por su parte, la especificidad es del `r paste0(round(mat_conf$n[1]/(mat_conf$n[1] + mat_conf$n[2])*100, 1), "%")`, lo cual sugiere que el modelo subestima la cantidad de veces que los estudiantes no aprueban un curso.

A continuación se presenta un gráfico con la importancia de cada variable. Como se puede ver, las variables que refieren a la edad de los estudiantes resultan ser las más importantes para este modelo. En general se observa que las variables numéricas se posicionan como las más relevantes. Por su parte, la categoría interior de las variables zona_nac y zona_ems también se encuentra entre las variables más importantes.

```{r}

bagging_test_results$.workflow[[1]]$fit$fit$fit$imp %>% 
  ggplot(aes(x = reorder(term, value), y = value)) +
  geom_bar(stat = "identity", , fill = "#76B7B2") +
  coord_flip() +
  geom_errorbar(aes(ymin = value - std.error, ymax = value + std.error), 
                width = 0.2, color = "red") +
  labs(x = "variable/categoría", y = "medida de importancia") +
    tema

```

## Vecino más cercano

```{r}
best_results_knn <- 
   grid_results %>% 
   extract_workflow_set_result("recipe_KNN") %>% 
   select_best(metric = "accuracy")

knn_test_results <- 
    grid_results %>% 
    extract_workflow("recipe_KNN") %>% 
    finalize_workflow(best_results_knn) %>% 
    last_fit(split = actres_split2)


mat_conf <- 
data.frame(knn_test_results$.predictions) |>
    count(aprobada, .pred_class) |> 
    mutate(.pred_class = factor(.pred_class,c(0,1))) 


mat_conf |> 
  ggplot(aes(x = aprobada, y = .pred_class)) +
  geom_tile(aes(fill = n)) +
  geom_text(aes(label = n), color = "white") +
  labs(x = "Observado", y = "Predicho") +
  theme(legend.position = "none") +
  tema


```

Del modelo del vecino mas cercano se observa una sensibilidad del `r paste0(round(mat_conf$n[4]/(mat_conf$n[4] + mat_conf$n[3])*100, 1), "%")`, lo cual predice bastante bien a los estudiantes que aprueban en curso, en este caso en particular queremos predecir los estudiantes que aprueban con alta precisión. Mientras que la precisión es del `r paste0(round((mat_conf$n[4] + mat_conf$n[1])/(nrow(actres_test2))*100, 1), "%")` y la especificidad del `r paste0(round(mat_conf$n[1]/(mat_conf$n[1] + mat_conf$n[2])*100, 1), "%")`.

## Comparación

Para finalizar, se presenta un cuadro con algunas métricas para cada uno de los modelos entrenados. En cuanto a medidas de error, todas presentan valores bajos como se puede ver en el cuadro. Sin embargo, los modelos de bosque aleatorio son los que arrojan mejores resultados. También se observa que la implementación del bagging no mejora significativamente el desempeño del random forest clásico.

```{r}
kable(select(best_results,c(model, .metric, mean, std_err, rank)), format="html", col.names = c("Modelo", "Métrica", "Media", "Desviación Estándar", "Ranking"))
```

Las curvas ROC de la figura 5 brindan la misma intuición que los cuadros. Se destaca la amplia similitud entre los modelos de bosque aleatorio.

```{r rocs, fig.cap = "Figura 5: comparación de curvas ROC para cada modelo"}
roc_rf <- roc(as.numeric(actres_test2$aprobada), rf_test_results$.predictions[[1]]$.pred_1)
roc_reglog <- roc(as.numeric(actres_test2$aprobada), reglog_test_results$.predictions[[1]]$.pred_1)
roc_bagging <- roc(as.numeric(actres_test2$aprobada), bagging_test_results$.predictions[[1]]$.pred_1)
roc_KNN <- roc(as.numeric(actres_test2$aprobada), bagging_test_results$.predictions[[1]]$.pred_1) # FALTA


ggplot() +
  geom_line(aes(x = 1 - roc_rf$specificities, y = roc_rf$sensitivities, color = "Random Forest"), size = 1) +
  geom_line(aes(x = 1 - roc_reglog$specificities, y = roc_reglog$sensitivities, color = "Logistic Regression"), size = 1) +
  geom_line(aes(x = 1 - roc_bagging$specificities, y = roc_bagging$sensitivities, color = "Bagging"), size = 1) +
  geom_abline(linetype = "dashed") + 
  labs(title = "Curvas ROC para varios modelos",
       x = "Tasa de Falsos Positivos",
       y = "Tasa de Verdaderos Positivos") +
  scale_color_manual(name = "Modelos", values = c("green", "red", "blue")) +
  theme_minimal()


```

# Conclusiones

En primer lugar, la selección de variables mediante el método de regularización de LASSO y el modelo de regresión logística fue clave para identificar las variables más relevantes. Posteriormente, se desarrollaron distintos modelos de clasificación con el objetivo de predecir, en la base de testeo, la probabilidad de aprobación de un curso del primer semestre. Se usaron distintas métricas como la matriz de confusión y la curva ROC para evaluar los distintos modelos, resultando el modelo de Random Forest y Bagging los mejores para identificar a los estudiantes que aprueban los cursos.

En lo que refiere a los errores de prediccion penalizando por el numero de parámetros y de observaciones $SEM = \sqrt\frac{\sum_{i=1}^n(y_i - \hat{y})^2}{n-p}$ resulto ser chico para todos los modelos. 

Tal como era de esperarse, las variables relacionadas a la edad son  las mas importantes para predecir la variable de respuesta de si el alumno aprueba o no el curso, algo que tiene sentido debido a que en promedio los estudiantes de menor edad tienen menos responsabilidades por fuera de la facultad, lo que hace que tengan mas tiempo de dedicación a los  cursos, mientras que por otra parte, contrario a lo que se esperaba podemos observar que el tipo de instancia previa del estudiante no resulto ser de las variables más relevantes, aunque dentro de esta, la categoría que mayor significación tuvo fue bachillerato público. 

A su vez, no se encontró evidencia de que la educación de los padres tenga relevancia para predecir la variable de respuesta, al igual que las variables que indican dificultades que tiene el estudiante para oír, caminar, etc. En el caso de estas variables, puede haber jugado en contra el desbalanceo, ya que los estudiantes con alguna dificultad son la minoría.

En cuanto a limitaciones y posibles mejoras a futuro, resalta la complejidad del conjunto de datos. Es importante mencionar que la variable con la que se trabajó, se tiene a un momento en el tiempo (en este caso, hasta 2021), pero el resultado del curso para cada estudiante puede cambiar en cuanto el estudiante vuelva a cursar la materia o de el examen tantas veces sea necesario para terminar aprobando el curso. por lo tanto, se está frente a un problema de datos censurados, donde el "0" en la variable aprobado indica que el estudiante no ha aprobado la materia en el tiempo de medición, pero es posible que lo apruebe en el futuro. Esto podría explicar que en determinados puntos de corte la especificidad de los modelos sea baja, dado que los atributos del estudiante podrían indicar que va a aprobar el curso, solo que todavía no lo ha hecho. En este sentido es que también resalta la importancia de la variable edad, que captura esta temporalidad.


**
Comentarios:

Al analizar dos generaciones tienen el problema que para una de ellas están mirando un año más que para la otra y eso es un problema, lo charlamos en clase pero no lo tomaron en cuenta.
Está bueno el intento que hicieron con shiny para ayudarse con la exploración y tener varias visualizaciones en un mismo lugar.
Figura 2 debieron poner etiquetas apropiadas a la variable tipo de inst. secundaria ya que con los valores numéricos no queda claro a que corresponde.
Pasa lo mismo en todas las otras visualizaciones donde la variable es categorica y no le pusieron etiqueta a la categoría, no queda claro.
En los resultados de los modelos no fueron muy claros y quedaron algunas cosas sin explicar o detallar.
No aclaran como fue la partición de los datos en entrenamiento y testeo, como seleccionaron las grillas para tunear los hiperparámetros, no queda claro porqué no tunearon algunas como mtry en RF que es relevante
Como comentamos en clase no queda claro que lo que usan de lasso es para seleccioanr variables y estas variables son las que van a ser usadas en los otros modelos . Tendrían que haber clarado eso mejor y no como parte de los modelos predictivos ya que lo usaron para seleccionar variables.
Ponen bosque aleatorio y random forest, consistencia con la terminologia.
Les faltó incorporar alguna de las medidas vistas de interpretabilidad.


Los datos son complejos eso les llevó tiempo entenderlos y restructurarlos para poder trabajarlos, creo que aprendieron bastante en el proceso !

Buen trabajo! 85/100**


# Referencias


